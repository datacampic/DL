{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "-490OsoUSiDt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN(Convolutional neural network)"
      ],
      "metadata": {
        "id": "okTHo7gpiSuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP의 한계"
      ],
      "metadata": {
        "id": "rLPu7YfvNF6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/mlp_overview.png\" height = 300 width = 400>"
      ],
      "metadata": {
        "id": "-1BojgDbMvkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/mlp_overview2.png\" height = 300 width = 400>"
      ],
      "metadata": {
        "id": "3kCT9DJPNmzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   MLP에서는 이미지 배열을 한줄로 쭉 펴서 확인하기 때문에 이미지의 특징을 찾기 힘들다.\n",
        "*   때문에 시간이 많이걸리고 결국 overfitting의 문제가 생긴다."
      ],
      "metadata": {
        "id": "AbEXU1q-N7pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "epsafK9aOQky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   CNN은 MLP의 한계를 개선하기 위해 등장하였다.\n",
        "*   CNN은 2D배열로 표현되어 뉴련을 입력과 연결하기 더 쉽다.\n",
        "*   CNN은 크게 합성곱층과 풀링층으로 구성된다.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F--yBmOYiatz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 시각피질 구조\n",
        "\n"
      ],
      "metadata": {
        "id": "BXM3ANwLDZ07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   신경망을 사람의 뇌를 기반으로 만들어졌다면 CNN은 사람의 시각피질을 본따서 만든 구조이다.\n",
        "\n",
        "*   CNN은 하위계층에서 이미지의 패턴을 찾고, 상위계층에서 그 패턴들을 조합함으로써 이미지를 추상화시킨다.\n",
        "\n",
        "*   CNN은 이미지 처리 문제에서 큰 성능을 발휘하여 이미지 검색 서비스, 자율주행 자동차, 영상 자동 분류 시스템 등에 활용된다\n",
        "\n",
        "\n",
        "*   CNN은 시각분야에 국한되지 않고 음성인식이나 자연어처리(NLP)에서도 많이 사용된다."
      ],
      "metadata": {
        "id": "sYAoPradDVCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 합성곱 층"
      ],
      "metadata": {
        "id": "g928kNmPGUv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   필터(커널) : 이미지의 특징을 찾아내기 위한 공용 파라미터로 합성곱 연산을 도와주는 배열 형태의 도구이다.\n",
        "*   스트라이드 : 필터를 순회하는 간격\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wAt7gDxvQcZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/stride.png\" width=500 height=150>\n",
        "\n",
        "\n",
        "> 5×5 데이터를 2×2 필터로 합성곱 연산\n",
        "\n"
      ],
      "metadata": {
        "id": "PaVQTDDmSer6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/elem_mul.png\" width = 500 height =400>\n",
        "\n",
        "> 합성곱 계산방법\n",
        "\n"
      ],
      "metadata": {
        "id": "ph7mLHPvSh-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/stride_result.png\" width = 500 height = 400>\n",
        "\n",
        "\n",
        "> 합성곱 연산 과정\n",
        "\n"
      ],
      "metadata": {
        "id": "qjyK9XG5SiBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   패딩 : 합성곱 층에서 합성곱 연산후 출력되는 Feature Map은 입력데이터보다 크기가 작다. 이를 방지하기 위한 방법인 패딩은 입력 데이터 외곽에 지정된 픽셀만큼 0으로 채우는 것을 말한다. 0으로 채우는 것을 제로패딩이라고도 한다,\n",
        "         ※ 패딩을 사용하는 이유 : 정보의 손실을 막고, CNN에게 패딩위치가 이미지의 끝부분임을 알려 줄 수 있음."
      ],
      "metadata": {
        "id": "6ndip-pOcB3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/zeropadding.png\" width = 500 height = 400>\n",
        "\n",
        "> 패딩\n",
        "\n"
      ],
      "metadata": {
        "id": "JCpCBFGfSiIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   채널 : 입력 이미지는 컬러 채널마다 하나씩 여러 서브 층으로 구성된다. 컬러 채널은 전형적으로 빨강, 초록, 파랑(RGB) 세가지를 가진다. 흑백이미지는 하나의 채널을 가진다. 합성곱 층에서 n개의 필터를 적용시키면 n개의 채널이 만들어진다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Grvj1ZYVcF4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://taewanmerepo.github.io/2018/01/cnn/conv2.jpg\" width = 500 height = 400>\n",
        "\n",
        "> 멀티 채널 입력데이터의 필터를 적용한 합성곱 계산 절차\n",
        "\n"
      ],
      "metadata": {
        "id": "226Edhs4V9Ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Convolution Layer의 입력데이터를 필터가 순회하여 만들어진 출력데이터를 Feature Map 또는 Activation Map이라고 한다. Feature Map은 합성곱 계산을 통해 만들어진 맴이다. Activation Map은 Feature Map에 활성 함수를 적용한 결과이다. 즉, Convolution Layer의 최종 출력 결과는 Activation Map이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "FgodMgkhWnKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 풀링층\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-490OsoUSiDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   풀링(Pooling) : 합성곱 연산을 거친 후 출력된 Feature Map의 크기를 줄이는 과정을 말한다. Feature map에 필터(커널)와 스트라이드 개념을 접목시켜 크기를 줄인다. 주로 최대 풀링(Max Pooling) 과 평균 풀링(Average Pooling)을 사용한다.\n",
        "   *   최대 풀링 : 필터에 포함된 값 중 가장 큰 값을 반환\n",
        "   *   평균 풀링 : 필터에 포함된 값들의 평균을 반환\n",
        "\n",
        "\n",
        "         ※ 일반적으로 평균풀링보다는 최대 풀링이 성능이 좋아서 최대풀링이 많이 쓰인다.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RFODU0-HVvDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://taewanmerepo.github.io/2018/02/cnn/maxpulling.png\" width = 500 height = 400>\n",
        "\n",
        "\n",
        "> 2×2 필터와 스트라이드 2로 최대풀링과 평균풀링 연산\n",
        "\n"
      ],
      "metadata": {
        "id": "CEqmuWvqVvF3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. CNN 구조"
      ],
      "metadata": {
        "id": "IYjt19qgVvIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   전형적인 CNN구조는 합성곱 층을 몇 개 쌓고, 그다음에 풀링층을 쌓고, 그다음에 또 합성곱 층을 몇개 더 쌓고, 그다음에 다시 풀링층을 쌓는 방식이다.\n",
        "*   CNN에서는 주로 활성화 함수는 Relu를 사용한다.\n",
        "*   CNN은 합성곱층과 풀링층을 이용하여 특성을 추출하고 그 뒤에 Fully Connected Layer를 쌓아서 추출한 특성을 이용한다.\n",
        "*   Fully Connected Layer에는 과대적합을 방지하기위한 Dropout층을 추가하고 마지막층에는 Softmax함수를 사용한다.\n"
      ],
      "metadata": {
        "id": "IYiYuegGVvKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/practice_cnn.png\" width=800 height=350>\n",
        "\n",
        "> CNN 기본 구조\n",
        "\n"
      ],
      "metadata": {
        "id": "wLdK_rLWSiK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LeNet-5"
      ],
      "metadata": {
        "id": "Tqfxxyb0SiNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://debuggercafe.com/wp-content/uploads/2019/07/Layers-in-LeNet.png\" width = 600 height =200>\n",
        "\n",
        "> LeNet-5 구조\n",
        "\n"
      ],
      "metadata": {
        "id": "b3WGA4tqYydd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    기본적으로 가장 많이 알려진 CNN구조로 1998년 얀 르쿤이 만들어 MNIST에 널리 사용되었다.\n",
        "*    MNIST는 28×28 픽셀이지만 제로패딩되어 32×32가 되고 네트워크에 주입되기전에 정규화 과정을 거친다. 나머지 네트워크에서는 패딩을 사용하지않아 점점 크기가 줄어든다.\n",
        "*    1번째 Layer : 32×32 이미지를 6개의 필터(5×5)와 합성곱 연산 수행 -> 6장의 27×28 특성 맵을 얻음\n",
        "*    2번째 Layer : 평균 풀링층으로 각 뉴런은 입력의 평균을 계산한 다음, 그 값에 학습되는 계숫값을 곱한다. 그리고 학습되는 값인 편향을 더한 후 마지막으로 활성화 함수를 적용\n",
        "      *  2×2 필터를 stride 2로 설정하여 특성맵이 절반(14×14)으로 축소됨\n",
        "*    3번째 Layer : 6장의 14×14 특성맵으로부터 16장의 10×10 특성맵이 산출됨\n",
        "      *  3번째 Layer의 뉴런은 2번째 Layer의 6개 맵 전체가 아니라 3~4개의 맵에 있는 뉴런에만 연결된다.\n",
        "<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcMVTPs%2FbtqQjm7R6gi%2FvMG47EhCRkrWC8ca0ii9OK%2Fimg.png\" width = 600 height = 300>\n",
        "\n",
        "\n",
        "*    4번째 Layer : 평균 풀링층으로 특성맵이 5×5로 축소됨\n",
        "*    5번째 Layer : 16개의 5×5 특성맵을 받아 5×5 크기의 커널120개와 합성곱을 수행하여 1×1 크기의 특성맵이 120개 산출\n",
        "*    6번째 Layer : tanh를 활성화 함수로 사용하는 Fully Connected Layer로 입력 유닛은 120개이고 출력 유닛은 84개이다.\n",
        "     *  84개로 만든이유는 ASCII set을 해석하기 적합한 형태로 만들기 위해서 설정했다고 한다. 각각의 문자가 7×12 크기의 bitmap 이기 때문.\n",
        "*    출력 Layer : RBF(Euclidean Radia Basis Function Unit)를 활성화 함수로 사용한 Output Layer이다. 입력과 가중치 벡터를 곱셈하는 대신 각 뉴런에서 입력벡터와 가중치 벡터 사이의 유클리드 거리를 출력한다. 입력 크기는 84고 출력크기는 10이다."
      ],
      "metadata": {
        "id": "OZ4n1EqPXetF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AlexNet"
      ],
      "metadata": {
        "id": "u9KqFblHrrGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   2012년 이미지넷 대회에서 Top-5 에러율 부분에서 17%를 기록하며 2위의 26%와 큰 격차를 벌이며 우승하였다. \n",
        "*   이 구조는 더 크고 깊을 뿐 LeNet-5와 비슷하다.\n",
        "*   이 구조를 통해서 CNN구조의 GPU 구현과 dropout 적용이 보편화 되었다.\n",
        "\n"
      ],
      "metadata": {
        "id": "CrgyFnBDrstU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-19-16-01-03.png\" width = 600 height = 400>\n",
        "\n",
        "> Alexnet 구조\n",
        "\n"
      ],
      "metadata": {
        "id": "L_Up4gcdrsvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-19-16-01-13.png\" width = 600 height = 300>\n",
        "\n",
        "> AlexNet Fully Conneted Layer와 Dropout 계층\n",
        "\n"
      ],
      "metadata": {
        "id": "VOVMi9oyrsx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* 2개의 Dropout 층과 3개의 Fully Connected Layer를 사용하였고 모든 층에서 ReLU 활성화 함수를 사용하고 출력층에서 Softmax 활성화 함수를 사용하였다.\n",
        "* Dropout층에서는 50%의 비율을 적용하여 Overfitting을 줄였다.\n",
        "* AlexNet은 C1과 C3 층의 ReLU 단계 후에 바로 LRN(Local Response Nomalization)이라 부르는 경쟁적인 정규화 단계를 사용했다.\n",
        "    * LRN : 가장 강하게 활성화된 뉴런이 다른 특성 맵에 있는 같은 위치의 뉴런을 억제 한다. 강조하고 싶은 부분을 확대하고, 나머지는 축소 시키는 방법이다. 이를 통해 더 좋은 일반화 결과를 도출하였다. 지금은 사용하지 않는다.\n",
        "* AlexNet 연구원들은 훈련 이미지를 랜덤하게 여러 간격으로 이동하거나 수평으로 뒤집고 조명을 바꾸는 식으로 데이터 증식(Data augmentation)을 수행하였다.\n",
        "    * 과대적합을 줄이는 규제 기법으로 사용할 수 있다.\n"
      ],
      "metadata": {
        "id": "bX-02fvVrs0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GoogleNet"
      ],
      "metadata": {
        "id": "nHYRqNmLrs2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   구글리서치에서 개발하여 Top-5 에러율을 7% 이하로 낮췄다.\n",
        "*   이전 CNN보다 훨씬 더 깊다.\n",
        "*   인셉션 모듈이라는 서브 네트워크를 가지고 있어 AlexNet보다 10배 적은 파라미터를 가진다.\n",
        "\n"
      ],
      "metadata": {
        "id": "iQnOdw0hrs49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://thebook.io/img/080263/232.jpg\" width = 600 height = 300>\n",
        "\n",
        "> 인셉션 모듈\n",
        "\n"
      ],
      "metadata": {
        "id": "gDO4QFMars7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   입력을 여러개로 분산한 후, 깊이를 기준으로 Concat한다.\n",
        "*   1×1층은 병목층 역할을 하며, 3×3, 5×5이전에 적용하여 연산비용을 줄일 수 있다.\n",
        "*   즉, 여러 크기의 복잡한 패턴을 가진 Feature Map을 출력하는 형태이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "cFKqhGq16FA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VGGNet"
      ],
      "metadata": {
        "id": "68oxY0lg26Sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 2014년 이미지 대회 2등인 VGGNet은 2개 또는 3개의 합성곱 층 뒤에 풀링 층이 나오고 다시 2개 또는 3개의 합성곱 층과 풀링층이 등장하는 식이다.(VGGNet 종류에 따라 총 16개 또는 19개의 합성곱 층이 존재한다.) VGGNet은 많은 개수의 필터를 사용하지만 3×3 필터만 사용한다."
      ],
      "metadata": {
        "id": "bxK0hRtk4Vt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ResNet"
      ],
      "metadata": {
        "id": "1BhbjUY54Vrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 잔차 네트워크를 사용해 2015년 이미지넷 대회에서 Top-5 에러율을 3.6%이하로 기록하며 우승했다.\n",
        "* 152개의 층으로 구성된 극도로 깊은 CNN을 사용\n",
        "* 깊은 층을 훈련시킬 수 있는 핵심 요소 -> 스킵 연결\n",
        "* 스킵 연결 : 어떤 층에 주입되는 신호가 상위 층의 출력에도 더해진다."
      ],
      "metadata": {
        "id": "x1ufTZFc4Vo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"http://i.imgur.com/Q9kYDvx.png\" width = 600 height = 300>\n",
        "\n",
        "> 잔차학습\n",
        "\n"
      ],
      "metadata": {
        "id": "SqNak0lc4Vmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   신경망을 훈련시킬 때는 목적 함수 h(x)를 모델링 하는 것이 목표\n",
        "*   입력 x를 네트워크 출력에 더하면(즉, 스킵연결 추가) 네트워크는 h(x) 대신 f(x) = h(x)-x를 학습하게 된다. 이를 잔차 학습이라고 한다.\n",
        "    * 일반적인 신경망을 초기화할 때는 가중치가 0에 가깝기 때문에 네트워크도 0에 가까운 값을 출력한다.\n",
        "    * 스킵연결을 추가하면 이 네트워크는 입력과 같은 값을 출력한다.\n",
        "    * 잔차학습에서 얻고자하는 출력값은 h(x) = f(x) + x이고, 모든 layer에서 gradient는 f'(x) + 1이기 때문에 최소 1이상 갖게 된다. -> 기울기 소실(gradient vanishing) 문제 해결 \n",
        "    * 목적 함수가 항등 함수에 매우 가깝다면 훈련 속도가 매우 빨라질 것이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "4Uh-YZLe4VkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"http://i.imgur.com/7tQQHxk.png?1\" width = 700 height = 200>\n",
        "\n",
        "\n",
        ">ResNet 구조\n",
        "\n"
      ],
      "metadata": {
        "id": "8oTl_fgh4Vh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Dropout층 제외 Googlenet과 같지만, 잔차 유닛을 매우 깊에 쌓음.\n",
        "* 각 잔차 유닛은 배치 정규화(BN)와 ReLU, 3×3 커널을 사용하고 공간정보를 유지하는(스트라이드 1, 'same' 패딩) 두개의 합성곱 층으로 이루어져 있다.\n",
        "* 특성 맵의 수는 몇 개의 잔차유닛마다 두 배로 늘어나고 높이와 너비는 절반이 된다.(스트라이드 2인 합성곱 층을 사용해서) 이때, 스트라이드가 2이고 출력 특성맵의 수가 같은 1×1 합성곱 층으로 입력을 통과시킨다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8mWYtlX4VfS"
      }
    }
  ]
}